{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import determinator\n",
    "import stanza\n",
    "import nafigator\n",
    "from collections import defaultdict, OrderedDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(\"P:\", \"projects\", \"tbx-data\", \"lassy\", \"WORD-LEMMA-POS.freq\"), \"r\", encoding=\"utf-8\")\n",
    "lines = file.readlines()\n",
    "\n",
    "lassy = {}\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    s = line.split(\" \")\n",
    "    data = s[1].split(\"\\t\")\n",
    "    if len(data)==3:\n",
    "        pos = data[2].split(\"(\")[0].replace(\"N\", \"noun\").replace(\"VZ\", \"adp\").lower()\n",
    "        morphofeats = \"(\"+data[2].split(\"(\")[1]\n",
    "        if (pos in [\"adj\", \"adp\", \"noun\"] or (pos ==\"spec\") and morphofeats==\"(afgebr)\") and len(data[0])>1:\n",
    "            if data[0] not in lassy.keys():\n",
    "                lassy[data[0]] = [{'lemma': data[1], \n",
    "                                  'partOfSpeech': pos,\n",
    "                                  'morphoFeats': morphofeats}]\n",
    "            else:\n",
    "                lassy[data[0]].append({'lemma': data[1], \n",
    "                                       'partOfSpeech': pos,\n",
    "                                       'morphoFeats': morphofeats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_components(filename, lassy):\n",
    "\n",
    "    file = open(filename, 'r', encoding=\"utf-8\")\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = line.split(\", \")\n",
    "        if len(data)==4:\n",
    "            pos = data[3].split(\"(\")[0].replace(\"N\", \"noun\").lower()\n",
    "            morphofeats = \"(\"+data[3].split(\"(\")[1][0:-1]\n",
    "            if data[1] not in lassy.keys():\n",
    "                lassy[data[1]] = [{'lemma': data[2], \n",
    "                                  'partOfSpeech': pos,\n",
    "                                  'morphoFeats': morphofeats}]\n",
    "            else:\n",
    "                lassy[data[1]].append({'lemma': data[2], \n",
    "                                       'partOfSpeech': pos,\n",
    "                                       'morphoFeats': morphofeats})\n",
    "    lassy = OrderedDict(sorted(lassy.items()))\n",
    "    \n",
    "    return lassy\n",
    "\n",
    "lassy = append_components(os.path.join(\"P:\", \"projects\", \"tbx-data\", \"lassy\", \"SOLVENCY2-LEMMA-POS.freq\"), lassy)\n",
    "lassy = append_components(os.path.join(\"P:\", \"projects\", \"tbx-data\", \"lassy\", \"CLIMATE-LEMMA-POS.freq\"), lassy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = determinator.TbxDocument()\n",
    "params = {\"sourceDesc\": \"TBX file, created via dnb/determinator\"}\n",
    "ref.generate(params)\n",
    "idx = 0\n",
    "for concept_text in lassy.keys():\n",
    "    for item in lassy[concept_text]:\n",
    "        concept = {\n",
    "                \"id\": \"c\"+str(idx+1),\n",
    "                \"langSec\": {\n",
    "                    \"nl\": [\n",
    "                        {\"type\": \"term\", \"text\": concept_text}]}}\n",
    "        idx += 1\n",
    "        concept['langSec']['nl'].append(\n",
    "                        {\n",
    "                            \"type\": \"termNote\",\n",
    "                            \"attr\": {\"type\": \"lemma\"},\n",
    "                            \"text\": item['lemma']})\n",
    "        concept['langSec']['nl'].append(\n",
    "                        {\n",
    "                            \"type\": \"termNote\",\n",
    "                            \"attr\": {\"type\": \"partOfSpeech\"},\n",
    "                            \"text\": item['partOfSpeech']})\n",
    "        concept['langSec']['nl'].append(\n",
    "                        {\n",
    "                            \"type\": \"termNote\",\n",
    "                            \"attr\": {\"type\": \"morphoFeats\"},\n",
    "                            \"text\": item['morphoFeats']})\n",
    "\n",
    "        ref.add_conceptEntry(concept=concept, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.write(os.path.join(\"P:\", \"projects\", \"tbx-data\", \"lassy\", \"lassy_with_insurance.tbx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
